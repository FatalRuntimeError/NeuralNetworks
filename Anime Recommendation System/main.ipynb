{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_anime = pd.read_csv('./dataset/anime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_anime = train_data_anime.drop([\"Name\", \"English name\", \"Date of premiere\", \"When aired\", \"Duration\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_anime['Avg score'].value_counts()\n",
    "train_data_anime['Avg score'] = train_data_anime['Avg score'].apply(lambda x: '5.00' if x == 'Unknown' else x)\n",
    "train_data_anime['Avg score'] = train_data_anime['Avg score'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ListToVec(names_list, data):\n",
    "    splitted = data.replace(' ', '').split(',')\n",
    "    vector = [0 for x in range(len(names_list))]\n",
    "    \n",
    "    for value in splitted:\n",
    "        vector[names_list.index(value)] = 1\n",
    "    \n",
    "    return vector\n",
    "\n",
    "def PreprocessList(data, column_name):\n",
    "    values = set()\n",
    "\n",
    "    for row in train_data_anime[column_name]:\n",
    "        for value in row.replace(' ', '').split(','):\n",
    "            values.add(value)\n",
    "\n",
    "    values_list = list(values) \n",
    "    data[column_name] = data[column_name].apply(lambda x: ListToVec(values_list, x))\n",
    "\n",
    "def PreprocessColumn(data, column_name):\n",
    "    values = set()\n",
    "    for row in train_data_anime[column_name]:\n",
    "            values.add(row)\n",
    "    values_list = list(values)\n",
    "    data[column_name] = data[column_name].apply(lambda x: values_list.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PreprocessColumn(train_data_anime, 'Type')\n",
    "PreprocessColumn(train_data_anime, 'Age limit')\n",
    "PreprocessColumn(train_data_anime, 'Based on')\n",
    "\n",
    "PreprocessList(train_data_anime, 'Genres')\n",
    "PreprocessList(train_data_anime, 'Producers')\n",
    "PreprocessList(train_data_anime, 'Licensors')\n",
    "PreprocessList(train_data_anime, 'Studios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_anime['Score count'] = float(0)\n",
    "\n",
    "for i in range(1, 11):\n",
    "    train_data_anime['Score-' + str(i)] = train_data_anime['Score-' + str(i)].apply(lambda x: '0.0' if x == 'Unknown' else x)\n",
    "    train_data_anime['Score-' + str(i)] = train_data_anime['Score-' + str(i)].apply(lambda x: float(x))\n",
    "    train_data_anime['Score count'] += train_data_anime['Score-' + str(i)]\n",
    "    train_data_anime = train_data_anime.drop('Score-' + str(i), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_anime['Num episodes'] = train_data_anime['Num episodes'].apply(lambda x: '36' if x == 'Unknown' else x)\n",
    "train_data_anime['Num episodes'] = train_data_anime['Num episodes'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [x for x in train_data_anime.columns if train_data_anime[x].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeMinMax(data, name):\n",
    "    data[name] = (data[name] - data[name].min()) / (data[name].max() - data[name].min())\n",
    "NormalizeMinMax(train_data_anime, 'Avg score')\n",
    "NormalizeMinMax(train_data_anime, 'Group members')\n",
    "NormalizeMinMax(train_data_anime, 'Num episodes')\n",
    "NormalizeMinMax(train_data_anime, 'In list')\n",
    "NormalizeMinMax(train_data_anime, 'In favourites')\n",
    "NormalizeMinMax(train_data_anime, 'Watching')\n",
    "NormalizeMinMax(train_data_anime, 'Finished')\n",
    "NormalizeMinMax(train_data_anime, 'On hold')\n",
    "NormalizeMinMax(train_data_anime, 'Dropped')\n",
    "NormalizeMinMax(train_data_anime, 'Finished')\n",
    "NormalizeMinMax(train_data_anime, 'Score count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user_id  anime_id  rating  watching_status  watched_episodes\n",
       "0        0       121       8                1                 0\n",
       "1        0     12815      10                1                 3\n",
       "2        0      3588       9                1                13\n",
       "3        0       392       8                3                 0\n",
       "4        1      1575       8                2                25"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>anime_id</th>\n      <th>rating</th>\n      <th>watching_status</th>\n      <th>watched_episodes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>121</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>12815</td>\n      <td>10</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>3588</td>\n      <td>9</td>\n      <td>1</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>392</td>\n      <td>8</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1575</td>\n      <td>8</td>\n      <td>2</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train_data_users = pd.read_csv('./dataset/user_ratings.csv')\n",
    "train_data_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import os\n",
    "import skorch\n",
    "import copy\n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch import NeuralNet\n",
    "from functools import reduce\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, code_size):\n",
    "        super(EncodeModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.code_size = code_size\n",
    "        self.encode = nn.Sequential(\n",
    "            #Encoder\n",
    "            nn.Linear(self.input_size, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size, self.code_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decode = nn.Sequential(\n",
    "            #Decoder\n",
    "            nn.Linear(self.code_size, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size, self.input_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "        return x\n",
    "    def encodeData(self, x):\n",
    "        return self.encode(x)\n",
    "\n",
    "def encode_cloumn(data, name, epochs = 10, predcompr = 4, compress = 6):\n",
    "    encoder = NeuralNet(\n",
    "        EncodeModel,\n",
    "        module__input_size = len(data[name][0]),\n",
    "        module__hidden_size = len(data[name][0]) // predcompr,\n",
    "        module__code_size= len(data[name][0]) // compress,\n",
    "        optimizer=torch.optim.Adam,\n",
    "        max_epochs=epochs,\n",
    "        lr=0.001,\n",
    "        criterion=nn.MSELoss,\n",
    "        # Shuffle training data on each epoch\n",
    "        iterator_train__shuffle=True,\n",
    "        batch_size=32,\n",
    "        device=device\n",
    "    )\n",
    "    data_tensor = torch.tensor(data[name], dtype=torch.float).to(device)\n",
    "    encoder.fit(data_tensor, data_tensor)\n",
    "    res = encoder.module_.encodeData(data_tensor)\n",
    "    data[name] = [x for x in res.cpu().detach().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m0.1236\u001b[0m        \u001b[32m0.0927\u001b[0m  1.0402\n",
      "      2        \u001b[36m0.0582\u001b[0m        \u001b[32m0.0834\u001b[0m  0.8596\n",
      "      3        \u001b[36m0.0508\u001b[0m        \u001b[32m0.0764\u001b[0m  0.8480\n",
      "      4        \u001b[36m0.0426\u001b[0m        \u001b[32m0.0673\u001b[0m  0.8432\n",
      "      5        \u001b[36m0.0387\u001b[0m        \u001b[32m0.0648\u001b[0m  0.8720\n",
      "      6        \u001b[36m0.0357\u001b[0m        \u001b[32m0.0595\u001b[0m  0.8622\n",
      "      7        \u001b[36m0.0324\u001b[0m        \u001b[32m0.0561\u001b[0m  0.8567\n",
      "      8        \u001b[36m0.0311\u001b[0m        \u001b[32m0.0548\u001b[0m  0.8489\n",
      "      9        \u001b[36m0.0303\u001b[0m        \u001b[32m0.0543\u001b[0m  0.8517\n",
      "     10        \u001b[36m0.0298\u001b[0m        \u001b[32m0.0541\u001b[0m  0.8549\n",
      "     11        \u001b[36m0.0294\u001b[0m        \u001b[32m0.0539\u001b[0m  0.8512\n",
      "     12        \u001b[36m0.0290\u001b[0m        \u001b[32m0.0531\u001b[0m  0.8438\n",
      "     13        \u001b[36m0.0287\u001b[0m        \u001b[32m0.0528\u001b[0m  0.8485\n",
      "     14        \u001b[36m0.0283\u001b[0m        \u001b[32m0.0521\u001b[0m  0.8499\n",
      "     15        \u001b[36m0.0279\u001b[0m        \u001b[32m0.0519\u001b[0m  0.8795\n",
      "     16        \u001b[36m0.0276\u001b[0m        \u001b[32m0.0515\u001b[0m  0.8524\n",
      "     17        \u001b[36m0.0273\u001b[0m        \u001b[32m0.0509\u001b[0m  0.8431\n",
      "     18        \u001b[36m0.0271\u001b[0m        \u001b[32m0.0506\u001b[0m  0.8476\n",
      "     19        \u001b[36m0.0269\u001b[0m        \u001b[32m0.0504\u001b[0m  0.8701\n",
      "     20        \u001b[36m0.0267\u001b[0m        \u001b[32m0.0502\u001b[0m  0.8683\n",
      "     21        \u001b[36m0.0265\u001b[0m        \u001b[32m0.0500\u001b[0m  0.8391\n",
      "     22        \u001b[36m0.0263\u001b[0m        \u001b[32m0.0497\u001b[0m  0.8444\n",
      "     23        \u001b[36m0.0261\u001b[0m        \u001b[32m0.0492\u001b[0m  0.8542\n",
      "     24        \u001b[36m0.0259\u001b[0m        \u001b[32m0.0489\u001b[0m  0.8458\n",
      "     25        \u001b[36m0.0256\u001b[0m        \u001b[32m0.0485\u001b[0m  0.8617\n",
      "     26        \u001b[36m0.0252\u001b[0m        \u001b[32m0.0476\u001b[0m  0.8485\n",
      "     27        \u001b[36m0.0248\u001b[0m        \u001b[32m0.0470\u001b[0m  0.8458\n",
      "     28        \u001b[36m0.0243\u001b[0m        \u001b[32m0.0459\u001b[0m  0.8420\n",
      "     29        \u001b[36m0.0238\u001b[0m        \u001b[32m0.0454\u001b[0m  0.8543\n",
      "     30        \u001b[36m0.0234\u001b[0m        \u001b[32m0.0448\u001b[0m  0.8466\n",
      "     31        \u001b[36m0.0231\u001b[0m        \u001b[32m0.0438\u001b[0m  0.8480\n",
      "     32        \u001b[36m0.0229\u001b[0m        \u001b[32m0.0436\u001b[0m  0.8404\n",
      "     33        \u001b[36m0.0226\u001b[0m        \u001b[32m0.0431\u001b[0m  0.9525\n",
      "     34        \u001b[36m0.0224\u001b[0m        \u001b[32m0.0425\u001b[0m  0.8667\n",
      "     35        \u001b[36m0.0222\u001b[0m        \u001b[32m0.0422\u001b[0m  0.8752\n",
      "     36        \u001b[36m0.0221\u001b[0m        \u001b[32m0.0421\u001b[0m  0.8580\n",
      "     37        \u001b[36m0.0219\u001b[0m        \u001b[32m0.0419\u001b[0m  0.8523\n",
      "     38        \u001b[36m0.0218\u001b[0m        \u001b[32m0.0418\u001b[0m  0.8386\n",
      "     39        \u001b[36m0.0217\u001b[0m        \u001b[32m0.0415\u001b[0m  0.8453\n",
      "     40        \u001b[36m0.0215\u001b[0m        0.0419  0.8431\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m0.0205\u001b[0m        \u001b[32m0.0013\u001b[0m  0.8495\n",
      "      2        \u001b[36m0.0009\u001b[0m        \u001b[32m0.0011\u001b[0m  0.8530\n",
      "      3        \u001b[36m0.0008\u001b[0m        \u001b[32m0.0011\u001b[0m  0.8505\n",
      "      4        \u001b[36m0.0008\u001b[0m        \u001b[32m0.0011\u001b[0m  0.8506\n",
      "      5        \u001b[36m0.0007\u001b[0m        \u001b[32m0.0010\u001b[0m  0.8527\n",
      "      6        \u001b[36m0.0007\u001b[0m        \u001b[32m0.0009\u001b[0m  0.8606\n",
      "      7        \u001b[36m0.0006\u001b[0m        \u001b[32m0.0009\u001b[0m  0.8587\n",
      "      8        \u001b[36m0.0006\u001b[0m        \u001b[32m0.0008\u001b[0m  0.8591\n",
      "      9        \u001b[36m0.0006\u001b[0m        \u001b[32m0.0008\u001b[0m  0.8543\n",
      "     10        \u001b[36m0.0005\u001b[0m        \u001b[32m0.0008\u001b[0m  0.8565\n",
      "     11        \u001b[36m0.0005\u001b[0m        \u001b[32m0.0008\u001b[0m  0.8534\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m0.0284\u001b[0m        \u001b[32m0.0015\u001b[0m  0.8432\n",
      "      2        \u001b[36m0.0009\u001b[0m        \u001b[32m0.0013\u001b[0m  0.8428\n",
      "      3        \u001b[36m0.0008\u001b[0m        \u001b[32m0.0012\u001b[0m  0.8646\n",
      "      4        \u001b[36m0.0008\u001b[0m        \u001b[32m0.0011\u001b[0m  0.8608\n",
      "      5        \u001b[36m0.0007\u001b[0m        \u001b[32m0.0010\u001b[0m  0.8559\n",
      "      6        \u001b[36m0.0006\u001b[0m        \u001b[32m0.0008\u001b[0m  0.8439\n",
      "      7        \u001b[36m0.0006\u001b[0m        \u001b[32m0.0007\u001b[0m  0.8522\n"
     ]
    }
   ],
   "source": [
    "encode_cloumn(train_data_anime, 'Genres', 40)\n",
    "encode_cloumn(train_data_anime, 'Producers', 11, 10, 20)\n",
    "encode_cloumn(train_data_anime, 'Studios', 7, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_anime = train_data_anime.drop('Type', axis=1)\n",
    "train_data_anime = train_data_anime.drop('Based on', axis=1)\n",
    "train_data_anime = train_data_anime.drop('Age limit', axis=1)\n",
    "train_data_anime = train_data_anime.drop('In list', axis=1)\n",
    "train_data_anime = train_data_anime.drop('Group members', axis=1)\n",
    "train_data_anime = train_data_anime.drop('Watching', axis=1)\n",
    "train_data_anime = train_data_anime.drop('On hold', axis=1)\n",
    "train_data_anime = train_data_anime.drop('Planning to watch', axis=1)\n",
    "train_data_anime = train_data_anime.drop('Num episodes', axis=1)\n",
    "train_data_anime = train_data_anime.drop('Licensors', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Id  Avg score                                             Genres  \\\n",
       "0   1   0.944142  [0.78121674, 7.308255, 10.646358, 0.49348742, ...   \n",
       "1   5   0.891008  [1.8854098, 6.075355, 10.155744, 0.0, 0.0, 8.9...   \n",
       "2   6   0.870572  [0.082239255, 5.939074, 12.262469, 0.0, 0.0, 9...   \n",
       "3   7   0.738420  [1.1217325, 0.0, 6.7350698, 1.996226, 0.0, 3.0...   \n",
       "4   8   0.698910  [3.6080043, 5.4485984, 2.9694827, 3.853971, 0....   \n",
       "\n",
       "                                           Producers  \\\n",
       "0  [0.6279943, 0.7098011, 0.26429427, 0.6122097, ...   \n",
       "1  [0.78828627, 0.83088404, 0.42312813, 0.7712970...   \n",
       "2  [0.45875385, 0.72369117, 0.42661017, 0.5238245...   \n",
       "3  [1.1320529, 1.4605576, 1.1861373, 1.3307332, 1...   \n",
       "4  [0.8291424, 1.2370769, 1.093889, 1.1105534, 0....   \n",
       "\n",
       "                                             Studios  In favourites  Finished  \\\n",
       "0  [0.0, 2.50786, 0.77700853, 4.7707176, 0.0, 0.0...       0.336956  0.329041   \n",
       "1  [0.0, 2.4009078, 0.50481653, 4.6601853, 0.0, 0...       0.006383  0.095452   \n",
       "2  [0.0, 3.7779198, 0.8860091, 1.2290316, 0.0, 0....       0.070381  0.157378   \n",
       "3  [0.0, 2.50786, 0.77700853, 4.7707176, 0.0, 0.0...       0.003192  0.021152   \n",
       "4  [0.0, 0.0, 0.28164282, 6.045031, 0.0, 0.0, 2.8...       0.000098  0.003351   \n",
       "\n",
       "    Dropped  Score count  \n",
       "0  0.152699     0.351294  \n",
       "1  0.004407     0.087781  \n",
       "2  0.079704     0.156647  \n",
       "3  0.030782     0.021402  \n",
       "4  0.006342     0.003242  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Avg score</th>\n      <th>Genres</th>\n      <th>Producers</th>\n      <th>Studios</th>\n      <th>In favourites</th>\n      <th>Finished</th>\n      <th>Dropped</th>\n      <th>Score count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.944142</td>\n      <td>[0.78121674, 7.308255, 10.646358, 0.49348742, ...</td>\n      <td>[0.6279943, 0.7098011, 0.26429427, 0.6122097, ...</td>\n      <td>[0.0, 2.50786, 0.77700853, 4.7707176, 0.0, 0.0...</td>\n      <td>0.336956</td>\n      <td>0.329041</td>\n      <td>0.152699</td>\n      <td>0.351294</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>0.891008</td>\n      <td>[1.8854098, 6.075355, 10.155744, 0.0, 0.0, 8.9...</td>\n      <td>[0.78828627, 0.83088404, 0.42312813, 0.7712970...</td>\n      <td>[0.0, 2.4009078, 0.50481653, 4.6601853, 0.0, 0...</td>\n      <td>0.006383</td>\n      <td>0.095452</td>\n      <td>0.004407</td>\n      <td>0.087781</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>0.870572</td>\n      <td>[0.082239255, 5.939074, 12.262469, 0.0, 0.0, 9...</td>\n      <td>[0.45875385, 0.72369117, 0.42661017, 0.5238245...</td>\n      <td>[0.0, 3.7779198, 0.8860091, 1.2290316, 0.0, 0....</td>\n      <td>0.070381</td>\n      <td>0.157378</td>\n      <td>0.079704</td>\n      <td>0.156647</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>0.738420</td>\n      <td>[1.1217325, 0.0, 6.7350698, 1.996226, 0.0, 3.0...</td>\n      <td>[1.1320529, 1.4605576, 1.1861373, 1.3307332, 1...</td>\n      <td>[0.0, 2.50786, 0.77700853, 4.7707176, 0.0, 0.0...</td>\n      <td>0.003192</td>\n      <td>0.021152</td>\n      <td>0.030782</td>\n      <td>0.021402</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>0.698910</td>\n      <td>[3.6080043, 5.4485984, 2.9694827, 3.853971, 0....</td>\n      <td>[0.8291424, 1.2370769, 1.093889, 1.1105534, 0....</td>\n      <td>[0.0, 0.0, 0.28164282, 6.045031, 0.0, 0.0, 2.8...</td>\n      <td>0.000098</td>\n      <td>0.003351</td>\n      <td>0.006342</td>\n      <td>0.003242</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "train_data_anime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_anime = dict()\n",
    "for row in train_data_anime.itertuples():\n",
    "    l = list()\n",
    "    for value in row:\n",
    "        value = list(value) if type(value) is np.ndarray else list([value])\n",
    "        l = l + value\n",
    "\n",
    "    data_anime[l[1]] = l[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_rating_list = [[] for _ in range(max(train_data_users['user_id']) + 1)]\n",
    "for row in train_data_users.itertuples():\n",
    "    if (row[3] != 0):\n",
    "        user_rating_list[row[1]].append([row[2], row[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_count = 70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "\n",
    "for user in user_rating_list[:user_count]:\n",
    "    if (len(user) > 0):     \n",
    "        max_value = max(user, key=lambda item: item[1])[1]\n",
    "        min_value = min(user, key=lambda item: item[1])[1]\n",
    "\n",
    "        for pair in user:\n",
    "            if max_value - min_value != 0:\n",
    "                targets.append((pair[1] - min_value)/(max_value - min_value))\n",
    "            else:\n",
    "                targets.append(pair[1])\n",
    "\n",
    "i = 0\n",
    "user_input = list()\n",
    "anime_input = list()\n",
    "for user in user_rating_list[:user_count]:\n",
    "    for pair in user:\n",
    "        user_input.append(i)\n",
    "        anime_input.append(data_anime[pair[0]])\n",
    "    \n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([5510475, 1]),\n",
       " torch.Size([5510475, 101]),\n",
       " torch.Size([5510475, 1]))"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "tensor_user_input = torch.tensor(user_input).reshape(-1, 1).to(device)\n",
    "tensor_anime_input = torch.tensor(anime_input).to(device)\n",
    "tensor_output = torch.tensor(targets).reshape(-1,1).to(device)\n",
    "\n",
    "tensor_user_input.shape, tensor_anime_input.shape, tensor_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiffModel, self).__init__()\n",
    "        self.embedding_vocabulary_size = 1100000\n",
    "        self.user_embedding_len = embedding_size\n",
    "        self.anime_embedding_len = 101\n",
    "        self.len = self.user_embedding_len + self.anime_embedding_len\n",
    "\n",
    "        self.sequen = nn.Sequential(\n",
    "            nn.Linear(self.len, self.len // 10),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(self.len // 10, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.embedding = nn.Embedding(self.embedding_vocabulary_size, self.user_embedding_len)\n",
    "\n",
    "    def forward(self, user_id, anime_embedding):\n",
    "        user_embedding = self.embedding(user_id)\n",
    "        user_embedding = user_embedding.reshape(-1, self.user_embedding_len)\n",
    "        \n",
    "        embedding = torch.cat((user_embedding, anime_embedding), 1) \n",
    "        result = self.sequen(embedding)\n",
    "\n",
    "        del user_embedding\n",
    "        del embedding\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffnet = NeuralNet(\n",
    "    DiffModel,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    max_epochs=6,\n",
    "    lr=0.01,\n",
    "    criterion=nn.MSELoss,\n",
    "    iterator_train__shuffle=True,\n",
    "    batch_size=32,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<class 'skorch.net.NeuralNet'>[initialized](\n",
       "  module_=DiffModel(\n",
       "    (sequen): Sequential(\n",
       "      (0): Linear(in_features=151, out_features=15, bias=True)\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): Linear(in_features=15, out_features=1, bias=True)\n",
       "      (3): Sigmoid()\n",
       "    )\n",
       "    (embedding): Embedding(1100000, 50)\n",
       "  ),\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "X = {\n",
    "    'user_id': tensor_user_input,\n",
    "    'anime_embedding': tensor_anime_input\n",
    "}\n",
    "\n",
    "diffnet.fit(X, tensor_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subm = []\n",
    "for el in submission['Id']:\n",
    "    pair = el.split(' ')\n",
    "    subm.append((int(pair[0]), int(pair[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "850000\n",
      "860000\n",
      "870000\n"
     ]
    }
   ],
   "source": [
    "def calcscore(id_user, id_anime, i):\n",
    "    user = user_rating_list[id_user]\n",
    "    if len(user) <= 1:\n",
    "        return train_data_anime[train_data_anime['Id'] == id_anime]['Avg score']\n",
    "    else:\n",
    "        max_value = max(user, key=lambda item: item[1])[1]\n",
    "        min_value = min(user, key=lambda item: item[1])[1]\n",
    "\n",
    "        anime_input = torch.tensor(data_anime[id_anime]).reshape(1, -1).to(device)\n",
    "        user_input = torch.tensor([id_user]).reshape(1, -1).to(device)\n",
    "        \n",
    "        pred = diffnet.predict({'user_id': user_input, 'anime_embedding': anime_input})\n",
    "\n",
    "        del anime_input\n",
    "        del user_input\n",
    "\n",
    "        return min_value + pred * (max_value - min_value)\n",
    "\n",
    "result = []\n",
    "progr = 0\n",
    "for elem in subm:\n",
    "    result.append(calcscore(elem[0], elem[1], progr))\n",
    "    progr += 1\n",
    "    if (progr % 10000 == 0):\n",
    "        print(progr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "proceed = []\n",
    "for el in result:\n",
    "    if isinstance(el, np.ndarray):\n",
    "        proceed.append(int(round(el.take(0))))\n",
    "    else:\n",
    "        proceed.append(int(round(9 * el + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "876529"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"submission.csv\", \"w\")\n",
    "file.write('Id,rating\\n')\n",
    "for id, rait in zip(subm,proceed):\n",
    "    file.write('{} {},{}\\n'.format(id[0], id[1], rait))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}